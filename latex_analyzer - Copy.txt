"""
Analizador de resultados de pruebas de visi√≥n artificial
Genera gr√°ficos, m√©tricas y tablas LaTeX para el reporte
INCLUYE: Parser de logs del modo local (ESP32) integrado
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import re
import os
import json
from datetime import datetime
from sklearn.metrics import confusion_matrix
import seaborn as sns

output_dir = "output_plots"
os.makedirs(output_dir, exist_ok=True)


class LocalLogParser:
    """Parser para logs del modo local ESP32"""
    
    def __init__(self, log_path: str, ground_truth_csv: str = "esp32_test.csv"):
        self.log_path = log_path
        self.ground_truth_csv = ground_truth_csv
        self.class_mapping = ['red', 'green', 'none', 'countdown_blank', 'countdown_green']
        self.ground_truth_df = None
        self.results = []
        
    def load_ground_truth(self):
        """Carga el CSV con las clases reales"""
        try:
            self.ground_truth_df = pd.read_csv(self.ground_truth_csv)
            print(f"‚úÖ Ground truth cargado: {len(self.ground_truth_df)} im√°genes")
            return True
        except Exception as e:
            print(f"‚ùå Error cargando ground truth: {e}")
            return False
    
    def parse_timestamp(self, ts_str: str) -> float:
        """Convierte T+HH:MM:SS.mmm a segundos totales"""
        try:
            ts_str = ts_str.replace("T+", "")
            parts = ts_str.split(":")
            hours = int(parts[0])
            minutes = int(parts[1])
            seconds = float(parts[2])
            
            total_seconds = hours * 3600 + minutes * 60 + seconds
            return total_seconds
        except Exception as e:
            print(f"‚ö†Ô∏è Error parseando timestamp '{ts_str}': {e}")
            return None
    
    def get_class_index(self, class_name: str) -> int:
        """Obtiene el √≠ndice de una clase"""
        class_lower = class_name.lower().replace(" ", "_")
        if class_lower in self.class_mapping:
            return self.class_mapping.index(class_lower)
        return -1
    
    def get_class_from_index(self, index: int) -> str:
        """Obtiene nombre de clase desde √≠ndice"""
        if 0 <= index < len(self.class_mapping):
            return self.class_mapping[index]
        return "unknown"
    
    def parse_log(self):
        """Parsea el archivo de log completo"""
        if not self.load_ground_truth():
            return False
        
        print(f"\nüìñ Parseando log: {self.log_path}")
        
        try:
            with open(self.log_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except Exception as e:
            print(f"‚ùå Error leyendo log: {e}")
            return False
        
        current_test = {}
        base_time = None
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # Extraer timestamp
            ts_match = re.match(r'(T\+\d{2}:\d{2}:\d{2}\.\d{3})', line)
            if not ts_match:
                continue
            
            timestamp_str = ts_match.group(1)
            timestamp = self.parse_timestamp(timestamp_str)
            
            if base_time is None:
                base_time = timestamp
            
            # Testing image
            if "Testing image:" in line:
                match = re.search(r'Testing image: (.+?\.(?:jpg|JPG|jpeg|png))\s+\((\d+)/(\d+)\)', line)
                if match:
                    filepath = match.group(1)
                    filename = os.path.basename(filepath)
                    test_num = int(match.group(2))
                    
                    current_test = {
                        'imagen': filename,
                        'test_num': test_num,
                        'timestamp_start': timestamp,
                        'timestamp_start_str': timestamp_str
                    }
            
            # All data sent
            elif "All data sent" in line and current_test:
                match = re.search(r'All data sent \((\d+) bytes\)', line)
                if match:
                    current_test['bytes_sent'] = int(match.group(1))
                    current_test['timestamp_sent'] = timestamp
                    current_test['timestamp_sent_str'] = timestamp_str
            
            # JSON response
            elif line.startswith('T+') and '{' in line and '"status"' in line:
                try:
                    json_str = line.split(' | INFO | ')[1]
                    response = json.loads(json_str)
                    
                    if current_test and 'timestamp_sent' in current_test:
                        current_test['timestamp_response'] = timestamp
                        current_test['timestamp_response_str'] = timestamp_str
                        current_test['prediction'] = response.get('prediction', 'unknown')
                        current_test['confidence'] = response.get('confidence', 0.0)
                        current_test['inference_time_ms'] = response.get('inference_time_ms', 0)
                        current_test['detected'] = response.get('detected', False)
                        
                        # Calcular latencia total (desde start hasta response)
                        current_test['latencia_total_ms'] = (current_test['timestamp_response'] - current_test['timestamp_start']) * 1000
                        
                        # Calcular latencia de red (desde sent hasta response)
                        current_test['latencia_red_ms'] = (current_test['timestamp_response'] - current_test['timestamp_sent']) * 1000
                        
                        # Latencia de env√≠o (desde start hasta sent)
                        current_test['latencia_envio_ms'] = (current_test['timestamp_sent'] - current_test['timestamp_start']) * 1000
                        
                        # Obtener clase real del ground truth
                        gt_row = self.ground_truth_df[
                            self.ground_truth_df['file'] == current_test['imagen']
                        ]
                        
                        if not gt_row.empty:
                            mode_index = int(gt_row.iloc[0]['mode'])
                            current_test['clase_real'] = self.get_class_from_index(mode_index)
                            current_test['clase_real_index'] = mode_index
                        else:
                            current_test['clase_real'] = 'unknown'
                            current_test['clase_real_index'] = -1
                            print(f"‚ö†Ô∏è No se encontr√≥ ground truth para: {current_test['imagen']}")
                        
                        # Mapear predicci√≥n
                        current_test['clase_pred'] = current_test['prediction'].lower().replace(" ", "_")
                        current_test['clase_pred_index'] = self.get_class_index(current_test['prediction'])
                        
                        # Calcular acierto
                        current_test['acierto'] = 1 if current_test['clase_real'] == current_test['clase_pred'] else 0
                        
                        # Guardar resultado
                        self.results.append(current_test.copy())
                        
                        # Reset para siguiente prueba
                        current_test = {}
                        
                except json.JSONDecodeError as e:
                    print(f"‚ö†Ô∏è Error parseando JSON en l√≠nea {i+1}: {e}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error procesando respuesta en l√≠nea {i+1}: {e}")
        
        print(f"‚úÖ Parseado completo: {len(self.results)} pruebas procesadas")
        return True
    
    def generate_simple_results_csv(self, output_path: str = None):
        """Genera CSV simple: imagen, clase_real, clase_pred, confianza, latencia_ms, acierto"""
        if not self.results:
            print("‚ùå No hay resultados para exportar")
            return None
        
        if output_path is None:
            output_path = os.path.join(output_dir, "resultados_modo_local.csv")
        
        df = pd.DataFrame(self.results)
        
        # Seleccionar y ordenar columnas
        output_df = df[[
            'imagen', 
            'clase_real', 
            'clase_pred', 
            'confidence', 
            'latencia_total_ms',
            'acierto'
        ]].copy()
        
        # Renombrar para formato final
        output_df.columns = ['imagen', 'clase_real', 'clase_pred', 'confianza', 'latencia_ms', 'acierto']
        
        # Guardar
        output_df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"‚úÖ CSV de resultados guardado: {output_path}")
        
        # Mostrar resumen
        print("\nüìä RESUMEN DE RESULTADOS:")
        print(f"   Total pruebas: {len(output_df)}")
        print(f"   Aciertos: {output_df['acierto'].sum()}")
        print(f"   Errores: {len(output_df) - output_df['acierto'].sum()}")
        print(f"   Precisi√≥n: {output_df['acierto'].mean() * 100:.2f}%")
        print(f"   Latencia media: {output_df['latencia_ms'].mean():.2f} ms")
        print(f"   Confianza media: {output_df['confianza'].mean():.4f}")
        
        return output_df
    
    def generate_confusion_matrix(self, output_path: str = None):
        """Genera y guarda la matriz de confusi√≥n"""
        if not self.results:
            print("‚ùå No hay resultados para generar matriz de confusi√≥n")
            return None
        
        if output_path is None:
            output_path = os.path.join(output_dir, "confusion_matrix_local.png")
        
        df = pd.DataFrame(self.results)
        df_valid = df[df['acierto'].notna()].copy()
        
        if df_valid.empty:
            print("‚ùå No hay datos v√°lidos para matriz de confusi√≥n")
            return None
        
        # Obtener clases √∫nicas en orden
        class_order = ['red', 'none', 'green', 'countdown_green', 'countdown_blank']
        
        # Generar matriz de confusi√≥n
        cm = confusion_matrix(
            df_valid['clase_real'], 
            df_valid['clase_pred'],
            labels=class_order
        )
        
        # Crear figura
        plt.figure(figsize=(10, 8))
        sns.heatmap(
            cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=class_order,
            yticklabels=class_order,
            cbar_kws={'label': 'Frecuencia'}
        )
        
        plt.title('Matriz de Confusi√≥n - Modo Local ESP32', fontsize=14, fontweight='bold')
        plt.ylabel('Clase Real (Ground Truth)', fontsize=12)
        plt.xlabel('Clase Predicha', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # Guardar
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"‚úÖ Matriz de confusi√≥n guardada: {output_path}")
        plt.close()
        
        return cm
    
    def calculate_local_metrics(self):
        """Calcula m√©tricas espec√≠ficas del modo local ESP32"""
        if not self.results:
            print("‚ùå No hay resultados para calcular m√©tricas")
            return None
        
        df = pd.DataFrame(self.results)
        
        # Filtrar solo resultados v√°lidos (con respuesta)
        df_valid = df[df['acierto'].notna()].copy()
        
        metrics = {
            'n_pruebas': len(df_valid),
            'aciertos': int(df_valid['acierto'].sum()),
            'errores': int(len(df_valid) - df_valid['acierto'].sum()),
            'precision_pct': round(df_valid['acierto'].mean() * 100, 2),
            
            # Latencia total (start -> response)
            'latencia_total_media_ms': round(df_valid['latencia_total_ms'].mean(), 2),
            'latencia_total_sd_ms': round(df_valid['latencia_total_ms'].std(), 2),
            'latencia_total_min_ms': round(df_valid['latencia_total_ms'].min(), 2),
            'latencia_total_max_ms': round(df_valid['latencia_total_ms'].max(), 2),
            'latencia_total_p95_ms': round(df_valid['latencia_total_ms'].quantile(0.95), 2),
            
            # Componentes de latencia
            'latencia_envio_media_ms': round(df_valid['latencia_envio_ms'].mean(), 2),
            'latencia_red_media_ms': round(df_valid['latencia_red_ms'].mean(), 2),
            'inference_time_media_ms': round(df_valid['inference_time_ms'].mean(), 2),
            
            # Confianza
            'confianza_media': round(df_valid['confidence'].mean(), 4),
            'confianza_sd': round(df_valid['confidence'].std(), 4),
            
            # Fallos de comunicaci√≥n
            'total_intentos': len(df),
            'fallos_comunicacion': len(df) - len(df_valid),
            'tasa_fallos_pct': round((len(df) - len(df_valid)) / len(df) * 100, 2) if len(df) > 0 else 0
        }
        
        return metrics
    
    def print_metrics_summary(self, metrics):
        """Imprime resumen de m√©tricas"""
        if not metrics:
            return
        
        print("\n" + "="*60)
        print("üìä M√âTRICAS DEL MODO LOCAL ESP32")
        print("="*60)
        
        print(f"\n‚úÖ ACCURACY:")
        print(f"   Predicciones correctas: {metrics['aciertos']}/{metrics['n_pruebas']}")
        print(f"   Accuracy: {metrics['precision_pct']:.2f}%")
        
        print(f"\n‚è±Ô∏è  LATENCIA TOTAL:")
        print(f"   Media: {metrics['latencia_total_media_ms']:.2f} ms")
        print(f"   Desv. Est: {metrics['latencia_total_sd_ms']:.2f} ms")
        print(f"   M√≠nima: {metrics['latencia_total_min_ms']:.2f} ms")
        print(f"   M√°xima: {metrics['latencia_total_max_ms']:.2f} ms")
        print(f"   P95: {metrics['latencia_total_p95_ms']:.2f} ms")
        
        print(f"\nüîß DESGLOSE DE LATENCIA:")
        print(f"   Env√≠o (ESP32): {metrics['latencia_envio_media_ms']:.2f} ms")
        print(f"   Inferencia (Servidor): {metrics['inference_time_media_ms']:.2f} ms")
        print(f"   Red (ida + vuelta): {metrics['latencia_red_media_ms']:.2f} ms")
        
        print(f"\nüì° COMUNICACI√ìN:")
        print(f"   Intentos totales: {metrics['total_intentos']}")
        print(f"   Respuestas exitosas: {metrics['n_pruebas']}")
        print(f"   Fallos: {metrics['fallos_comunicacion']}")
        print(f"   Tasa de fallos: {metrics['tasa_fallos_pct']:.2f}%")
        
        print(f"\nüéØ CONFIANZA:")
        print(f"   Media: {metrics['confianza_media']:.4f}")
        print(f"   Desv. Est: {metrics['confianza_sd']:.4f}")


class TestAnalyzer:
    def __init__(self, csv_path: str = "resultados_pruebas_20260104_161812 (wip).csv", 
                 local_log_path: str = None, ground_truth_csv: str = None):
        self.csv_path = csv_path
        self.local_log_path = local_log_path
        self.ground_truth_csv = ground_truth_csv
        self.df = None
        self.metrics = {}
        self.local_parser = None
        
    def load_data(self):
        """Carga el CSV de resultados y opcionalmente integra logs locales"""
        try:
            # Cargar CSV principal
            try:
                self.df = pd.read_csv(self.csv_path, encoding='utf-8-sig')
            except:
                self.df = pd.read_csv(self.csv_path, encoding='utf-8')
            
            print(f"‚úÖ CSV cargado: {len(self.df)} registros")
            print(f"üìã Columnas: {list(self.df.columns)}")
            
            # Si hay logs locales, integrarlos
            if self.local_log_path and self.ground_truth_csv:
                print("\nüîÑ Integrando datos del modo local...")
                self._integrate_local_logs()
            
            # Convertir latencia y t_total_ms
            if 'latencia' in self.df.columns:
                self.df['latencia_ms'] = self.df['latencia'].apply(self.mmss_to_seconds)
                
            if 't_total_ms' in self.df.columns:
                self.df['t_total_ms_numeric'] = self.df['t_total_ms'].apply(self.mmss_to_seconds)
            
            # Convertir confianza a num√©rico
            if 'confianza' in self.df.columns:
                self.df['confianza'] = pd.to_numeric(self.df['confianza'], errors='coerce')
            
            # Procesar DEPTH
            self.df['distancia_verdad_cm'] = self.df.apply(
                lambda row: self.extract_depth_ground_truth(row) 
                if row.get('tipo_evento') == 'DEPTH' else None, 
                axis=1
            )
            
            self.df['distancia_estimada_cm'] = self.df.apply(
                lambda row: self.extract_distance(row.get('objeto_predicho')) 
                if row.get('tipo_evento') == 'DEPTH' else None, 
                axis=1
            )
            
            # Calcular diferencias de distancia
            self.df['diferencia_distancia_pct'] = self.df.apply(
                lambda row: self.calculate_distance_error(
                    row.get('distancia_verdad_cm'), 
                    row.get('distancia_estimada_cm')
                ), axis=1
            )
            
            self.df['clasificacion_distancia'] = self.df['diferencia_distancia_pct'].apply(
                self.classify_distance_error
            )
            
            # Procesar OCR
            self.df['texto_verdad'] = self.df.apply(
                lambda row: self.extract_ocr_ground_truth(row) 
                if row.get('tipo_evento') == 'OCR' else None, 
                axis=1
            )
            
            self.df['texto_predicho'] = self.df.apply(
                lambda row: self.extract_ocr_predicted(row) 
                if row.get('tipo_evento') == 'OCR' else None, 
                axis=1
            )
            
            return True
        except Exception as e:
            print(f"‚ùå Error al cargar datos: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def _integrate_local_logs(self):
        """Integra los logs del modo local al DataFrame principal"""
        self.local_parser = LocalLogParser(self.local_log_path, self.ground_truth_csv)
        
        if not self.local_parser.parse_log():
            print("‚ö†Ô∏è No se pudieron integrar los logs locales")
            return
        
        # Obtener el ID m√°ximo actual
        max_id = self.df['id_prueba'].max() if 'id_prueba' in self.df.columns else 0
        
        # Crear nuevas filas para cada resultado LOCAL
        new_rows = []
        
        for idx, result in enumerate(self.local_parser.results):
            row_id = max_id + idx + 1
            
            # Crear timestamp ficticio (usar la fecha del √∫ltimo registro o actual)
            if not self.df.empty and 'timestamp' in self.df.columns:
                last_ts = pd.to_datetime(self.df['timestamp'].iloc[-1])
                timestamp = last_ts + pd.Timedelta(seconds=idx*10)
            else:
                timestamp = datetime.now() + pd.Timedelta(seconds=idx*10)
            
            # Formatear latencia en formato MM:SS.s
            latencia_seconds = result['latencia_total_ms'] / 1000
            latencia_formatted = f"{int(latencia_seconds // 60):02d}:{latencia_seconds % 60:04.1f}"
            
            new_row = {
                'id_prueba': row_id,
                'timestamp': timestamp,
                'interaccion': 'LOCAL',
                'modo': 'LOCAL',
                'tipo_evento': 'SCENE',
                'escenario': result['imagen'],
                'objeto_verdad': result['clase_real'],
                'objeto_predicho': result['clase_pred'],
                'distancia_m': None,
                'confianza': result['confidence'],
                'latencia': latencia_formatted,
                't_total_ms': None,
                'audio_path': None,
                'notas': f"Test {result['test_num']}: {result['bytes_sent']} bytes"
            }
            
            new_rows.append(new_row)
        
        # Agregar las nuevas filas al DataFrame
        if new_rows:
            new_df = pd.DataFrame(new_rows)
            self.df = pd.concat([self.df, new_df], ignore_index=True)
            print(f"‚úÖ {len(new_rows)} registros del modo local integrados")
    
    def extract_distance(self, dist_str) -> float:
        """Extrae valor num√©rico de distancia en cm"""
        if pd.isna(dist_str):
            return None
        
        try:
            dist_str = str(dist_str).strip()
            if not dist_str or dist_str in ['', 'nan', 'None']:
                return None
            
            match = re.search(r'(\d+\.?\d*)\s*cm', dist_str, re.IGNORECASE)
            if match:
                return float(match.group(1))
            
            try:
                return float(dist_str)
            except:
                return None
        except Exception:
            return None
    
    def extract_depth_ground_truth(self, row) -> float:
        """Extrae la distancia verdad de DEPTH"""
        if pd.notna(row.get('objeto_verdad')):
            obj_verdad = str(row['objeto_verdad']).strip()
            if obj_verdad and obj_verdad.lower() != 'nan':
                dist = self.extract_distance(obj_verdad)
                if dist is not None:
                    return dist
        
        if pd.notna(row.get('distancia_m')):
            try:
                return float(row['distancia_m']) * 100
            except:
                pass
        
        escenario = row.get('escenario', '')
        if pd.notna(escenario):
            escenario_str = str(escenario)
            match = re.search(r'(\d+\.?\d*)\s*cm', escenario_str, re.IGNORECASE)
            if match:
                return float(match.group(1))
            match = re.search(r'(\d+\.?\d*)\s*m\b', escenario_str, re.IGNORECASE)
            if match:
                return float(match.group(1)) * 100
        
        return None
    
    def extract_ocr_ground_truth(self, row) -> str:
        """Extrae el texto verdad de OCR"""
        if pd.notna(row.get('objeto_verdad')):
            obj_verdad = str(row['objeto_verdad']).strip()
            if obj_verdad and obj_verdad.lower() not in ['nan', '', 'none']:
                return obj_verdad
        return None
    
    def extract_ocr_predicted(self, row) -> str:
        """Extrae el texto predicho de OCR"""
        notas = row.get('notas')
        if pd.notna(notas):
            notas_str = str(notas)
            match = re.search(r'result:\s*["\']([^"\']+)["\']', notas_str, re.IGNORECASE | re.DOTALL)
            if match:
                resultado = match.group(1).strip()
                resultado = ' '.join(resultado.split())
                return resultado
        
        if pd.notna(row.get('objeto_predicho')):
            obj_pred = str(row['objeto_predicho']).strip()
            if not re.search(r'\d+\.?\d*\s*cm', obj_pred, re.IGNORECASE):
                return obj_pred
        
        return None
    
    def calculate_distance_error(self, real, estimada) -> float:
        """Calcula error porcentual"""
        if pd.isna(real) or pd.isna(estimada) or real == 0:
            return None
        
        try:
            error_pct = (abs(real - estimada) / real) * 100
            return round(error_pct, 2)
        except:
            return None
    
    def classify_distance_error(self, error_pct) -> str:
        """Clasifica error de distancia"""
        if pd.isna(error_pct):
            return None
        
        if error_pct < 20:
            return 'Acierto'
        elif error_pct <= 50:
            return 'Error parcial'
        else:
            return 'Fallo'
    
    def mmss_to_seconds(self, time_str: str) -> float:
        """Convierte MM:SS.s o HH:MM:SS.s a segundos"""
        if pd.isna(time_str):
            return None

        try:
            time_str = str(time_str).strip()
            if time_str == "":
                return None

            is_negative = time_str.startswith("-")
            if is_negative:
                time_str = time_str[1:]

            parts = time_str.split(":")

            if len(parts) == 2:
                minutes = int(parts[0])
                seconds = float(parts[1])
                total_seconds = minutes * 60 + seconds
            elif len(parts) == 3:
                hours = int(parts[0])
                minutes = int(parts[1])
                seconds = float(parts[2])
                total_seconds = hours * 3600 + minutes * 60 + seconds
            else:
                return None

            return -total_seconds if is_negative else total_seconds

        except Exception:
            return None
    
    def calculate_text_similarity(self, ground_truth: str, predicted: str) -> float:
        """Calcula similitud usando distancia de Levenshtein"""
        gt = str(ground_truth).lower().strip()
        pred = str(predicted).lower().strip()
        
        if gt == pred:
            return 1.0
        
        if not gt or not pred:
            return 0.0
        
        distance = self.levenshtein_distance(gt, pred)
        max_len = max(len(gt), len(pred))
        similarity = 1.0 - (distance / max_len)
        
        return max(0.0, similarity)
    
    def levenshtein_distance(self, s1: str, s2: str) -> int:
        """Distancia de Levenshtein"""
        if len(s1) < len(s2):
            return self.levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def calculate_all_metrics(self):
        """Calcula todas las m√©tricas necesarias para las tablas"""
        print("\n" + "="*60)
        print("üìä CALCULANDO M√âTRICAS PARA TABLAS")
        print("="*60)
        
        metrics = {
            'LOCAL': {},
            'MOBILE_SCENE': {},
            'MOBILE_OCR': {},
            'MOBILE_DEPTH': {},
            'MOBILE_GENERAL': {}
        }
        
        # === MODO LOCAL ===
        df_local = self.df[self.df['modo'] == 'LOCAL']
        if not df_local.empty:
            metrics['LOCAL'] = self._calculate_mode_metrics(df_local, 'LOCAL')
        else:
            print("‚ö†Ô∏è No hay datos de Modo Local")
        
        # === MODO H√çBRIDO - SCENE ===
        df_scene = self.df[(self.df['modo'] == 'MOBILE') & (self.df['tipo_evento'] == 'SCENE')]
        if not df_scene.empty:
            metrics['MOBILE_SCENE'] = self._calculate_scene_metrics(df_scene)
        
        # === MODO H√çBRIDO - OCR ===
        df_ocr = self.df[(self.df['modo'] == 'MOBILE') & (self.df['tipo_evento'] == 'OCR')]
        if not df_ocr.empty:
            metrics['MOBILE_OCR'] = self._calculate_ocr_metrics(df_ocr)
        
        # === MODO H√çBRIDO - DEPTH ===
        df_depth = self.df[(self.df['modo'] == 'MOBILE') & (self.df['tipo_evento'] == 'DEPTH')]
        if not df_depth.empty:
            metrics['MOBILE_DEPTH'] = self._calculate_depth_metrics(df_depth)
        
        # === MODO H√çBRIDO GENERAL ===
        df_mobile = self.df[self.df['modo'] == 'MOBILE']
        if not df_mobile.empty:
            metrics['MOBILE_GENERAL'] = self._calculate_mode_metrics(df_mobile, 'MOBILE')
        
        self.metrics = metrics
        return metrics
    
    def _calculate_mode_metrics(self, df, mode_name):
        """Calcula m√©tricas generales para un modo"""
        metrics = {
            'n_pruebas': len(df),
            'aciertos': 0,
            'errores': 0,
            'precision_pct': 0.0,
            'fallos': 0,
            'tasa_fallos_pct': 0.0
        }
        
        # Para LOCAL, calcular aciertos basado en objeto_verdad vs objeto_predicho
        if mode_name == 'LOCAL':
            df_valid = df[(df['objeto_verdad'].notna()) & (df['objeto_predicho'].notna())]
            if not df_valid.empty:
                aciertos = (df_valid['objeto_verdad'] == df_valid['objeto_predicho']).sum()
                metrics['aciertos'] = int(aciertos)
                metrics['errores'] = len(df_valid) - int(aciertos)
                metrics['precision_pct'] = round((aciertos / len(df_valid) * 100), 2)
        
        # Latencia
        df_lat = df[df['latencia_ms'].notna()]
        if not df_lat.empty:
            metrics['latencia_media_ms'] = df_lat['latencia_ms'].mean() * 1000
            metrics['latencia_sd_ms'] = df_lat['latencia_ms'].std() * 1000
            metrics['latencia_min_ms'] = df_lat['latencia_ms'].min() * 1000
            metrics['latencia_max_ms'] = df_lat['latencia_ms'].max() * 1000
        
        return metrics
    
    def _calculate_system_latency_from_sequences(self, df_filtered, event_type):
        """Calcula latencia del sistema bas√°ndose en secuencias de eventos cercanos"""
        latencies = []
        df_sorted = df_filtered.sort_values('id_prueba').copy()
        
        if df_sorted['timestamp'].dtype == 'object':
            df_sorted['timestamp'] = pd.to_datetime(df_sorted['timestamp'])
        
        esp32_finished = df_sorted[
            (df_sorted['tipo_evento'] == 'ESP32') & 
            (df_sorted['notas'].str.contains('finished.*bytes', na=False, regex=True))
        ].copy()
        
        for idx, esp32_row in esp32_finished.iterrows():
            next_events = df_sorted[
                (df_sorted['id_prueba'] > esp32_row['id_prueba']) &
                (df_sorted['tipo_evento'] == event_type)
            ]
            
            if event_type == 'SCENE':
                result_event = next_events[next_events['objeto_predicho'].notna()]
            elif event_type == 'OCR':
                result_event = next_events[
                    next_events['notas'].str.contains('result:', na=False, case=False)
                ]
            elif event_type == 'DEPTH':
                result_event = next_events[
                    next_events['notas'].str.contains('done. minDistance', na=False, case=False)
                ]
            else:
                continue
            
            if result_event.empty:
                continue
            
            result_row = result_event.iloc[0]
            
            middle_esp32 = df_sorted[
                (df_sorted['id_prueba'] > esp32_row['id_prueba']) &
                (df_sorted['id_prueba'] < result_row['id_prueba']) &
                (df_sorted['tipo_evento'] == 'ESP32') &
                (df_sorted['notas'].str.contains('finished.*bytes', na=False, regex=True))
            ]
            
            if not middle_esp32.empty:
                continue
            
            tts_window = df_sorted[
                (df_sorted['id_prueba'] > result_row['id_prueba']) &
                (df_sorted['id_prueba'] <= result_row['id_prueba'] + 20) &
                (df_sorted['tipo_evento'] == 'TTS') &
                (df_sorted['notas'].str.contains('converted output to speech', na=False, case=False))
            ]
            
            if not tts_window.empty:
                tts_row = tts_window.iloc[0]
                latency = (tts_row['timestamp'] - esp32_row['timestamp']).total_seconds()
            else:
                latency = (result_row['timestamp'] - esp32_row['timestamp']).total_seconds()
            
            if 0 < latency < 30:
                latencies.append(latency)
        
        return latencies

    def _calculate_scene_metrics(self, df_scene):
        """Calcula m√©tricas espec√≠ficas de SCENE"""
        df_valid = df_scene[
            (df_scene['objeto_verdad'].notna()) & 
            (df_scene['objeto_verdad'] != '')
        ].copy()
        
        total = len(df_valid)
        aciertos = (df_valid['objeto_verdad'] == df_valid['objeto_predicho']).sum()
        errores = total - aciertos
        precision = (aciertos / total * 100) if total > 0 else 0
        
        metrics = {
            'n_pruebas': total,
            'aciertos': int(aciertos),
            'errores': int(errores),
            'precision_pct': round(precision, 2),
            'fallos': 0,
            'tasa_fallos_pct': 0.0
        }
        
        df_scene_full = self.df[(self.df['modo'] == 'MOBILE') & 
                                (self.df['tipo_evento'].isin(['ESP32', 'SCENE', 'TTS']))]
        latencies = self._calculate_system_latency_from_sequences(df_scene_full, 'SCENE')
        
        if latencies:
            latencies_ms = [l * 1000 for l in latencies]
            metrics['latencia_media_ms'] = np.mean(latencies_ms)
            metrics['latencia_sd_ms'] = np.std(latencies_ms)
            metrics['latencia_min_ms'] = np.min(latencies_ms)
            metrics['latencia_max_ms'] = np.max(latencies_ms)
        
        return metrics
    
    def _calculate_ocr_metrics(self, df_ocr):
        """Calcula m√©tricas espec√≠ficas de OCR"""
        df_valid = df_ocr[
            (df_ocr['texto_verdad'].notna()) & 
            (df_ocr['texto_predicho'].notna())
        ].copy()
        
        if df_valid.empty:
            return {'n_pruebas': 0, 'aciertos': 0, 'errores': 0, 'precision_pct': 0.0}
        
        df_valid['acierto'] = df_valid.apply(
            lambda row: 1 if self.calculate_text_similarity(
                str(row['texto_verdad']), str(row['texto_predicho'])
            ) >= 0.8 else 0, axis=1
        )
        
        total = len(df_valid)
        aciertos = df_valid['acierto'].sum()
        errores = total - aciertos
        precision = (aciertos / total * 100) if total > 0 else 0
        
        metrics = {
            'n_pruebas': total,
            'aciertos': int(aciertos),
            'errores': int(errores),
            'precision_pct': round(precision, 2),
            'fallos': 0,
            'tasa_fallos_pct': 0.0
        }
        
        df_ocr_full = self.df[(self.df['modo'] == 'MOBILE') & 
                              (self.df['tipo_evento'].isin(['ESP32', 'OCR', 'TTS']))]
        latencies = self._calculate_system_latency_from_sequences(df_ocr_full, 'OCR')
        
        if latencies:
            latencies_ms = [l * 1000 for l in latencies]
            metrics['latencia_media_ms'] = np.mean(latencies_ms)
            metrics['latencia_sd_ms'] = np.std(latencies_ms)
            metrics['latencia_min_ms'] = np.min(latencies_ms)
            metrics['latencia_max_ms'] = np.max(latencies_ms)
        
        return metrics
    
    def _calculate_depth_metrics(self, df_depth):
        """Calcula m√©tricas espec√≠ficas de DEPTH"""
        df_valid = df_depth[
            (df_depth['distancia_verdad_cm'].notna()) & 
            (df_depth['distancia_estimada_cm'].notna())
        ].copy()
        
        if df_valid.empty:
            return {'n_pruebas': 0, 'aciertos': 0, 'errores': 0, 'precision_pct': 0.0}
        
        total = len(df_valid)
        aciertos = (df_valid['clasificacion_distancia'] == 'Acierto').sum()
        errores = total - aciertos
        precision = (aciertos / total * 100) if total > 0 else 0
        
        metrics = {
            'n_pruebas': total,
            'aciertos': int(aciertos),
            'errores': int(errores),
            'precision_pct': round(precision, 2),
            'fallos': 0,
            'tasa_fallos_pct': 0.0
        }
        
        df_depth_full = self.df[(self.df['modo'] == 'MOBILE') & 
                                (self.df['tipo_evento'].isin(['ESP32', 'DEPTH', 'TTS', 'HAPTIC']))]
        latencies = self._calculate_system_latency_from_sequences(df_depth_full, 'DEPTH')
        
        if latencies:
            latencies_ms = [l * 1000 for l in latencies]
            metrics['latencia_media_ms'] = np.mean(latencies_ms)
            metrics['latencia_sd_ms'] = np.std(latencies_ms)
            metrics['latencia_min_ms'] = np.min(latencies_ms)
            metrics['latencia_max_ms'] = np.max(latencies_ms)
        
        return metrics
    
    def generate_latex_tables(self):
        """Genera todas las tablas LaTeX"""
        if not self.metrics:
            self.calculate_all_metrics()
        
        print("\n" + "="*60)
        print("üìÑ GENERANDO TABLAS LATEX")
        print("="*60)
        
        tables = []
        tables.append(self._generate_precision_global_table())
        tables.append(self._generate_precision_escenario_table())
        tables.append(self._generate_latencia_sistema_table())
        tables.append(self._generate_latencia_componentes_table())
        tables.append(self._generate_tasa_fallos_table())
        
        output_file = os.path.join(output_dir, 'tablas_latex.txt')
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n\n'.join(tables))
        
        print(f"\n‚úÖ Tablas guardadas en: {output_file}")
        
        for table in tables:
            print("\n" + table)
        
        return tables
    
    def _generate_precision_global_table(self):
        """Tabla 1: Precisi√≥n global"""
        m = self.metrics
        
        def get_val(key, field, default='N/A'):
            return m.get(key, {}).get(field, default)
        
        table = r"""\begin{table}[H]
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Modalidad} & \textbf{N¬∞ pruebas} & \textbf{Aciertos} & \textbf{Errores} & \textbf{Precisi√≥n (\%)} \\
\midrule"""
        
        table += f"\nModo Local & {get_val('LOCAL', 'n_pruebas', 0)} & {get_val('LOCAL', 'aciertos', 0)} & {get_val('LOCAL', 'errores', 0)} & {get_val('LOCAL', 'precision_pct', 0):.2f} \\\\"
        table += f"\nModo H√≠brido - Scene & {get_val('MOBILE_SCENE', 'n_pruebas', 0)} & {get_val('MOBILE_SCENE', 'aciertos', 0)} & {get_val('MOBILE_SCENE', 'errores', 0)} & {get_val('MOBILE_SCENE', 'precision_pct', 0):.2f} \\\\"
        table += f"\nModo H√≠brido - OCR & {get_val('MOBILE_OCR', 'n_pruebas', 0)} & {get_val('MOBILE_OCR', 'aciertos', 0)} & {get_val('MOBILE_OCR', 'errores', 0)} & {get_val('MOBILE_OCR', 'precision_pct', 0):.2f} \\\\"
        table += f"\nModo H√≠brido - Depth & {get_val('MOBILE_DEPTH', 'n_pruebas', 0)} & {get_val('MOBILE_DEPTH', 'aciertos', 0)} & {get_val('MOBILE_DEPTH', 'errores', 0)} & {get_val('MOBILE_DEPTH', 'precision_pct', 0):.2f} \\\\"
        
        table += r"""
\bottomrule
\end{tabular}
\caption{Precisi√≥n global del prototipo por modalidad}
\label{tab:precision-global}
\end{table}"""
        
        return table
    
    def _generate_precision_escenario_table(self):
        """Tabla 2: Precisi√≥n por escenario"""
        escenarios = {}
        
        for modo in ['LOCAL', 'MOBILE']:
            df_modo = self.df[self.df['modo'] == modo]
            if df_modo.empty:
                continue
            
            for escenario in df_modo['escenario'].unique():
                if pd.isna(escenario):
                    continue
                    
                df_esc = df_modo[df_modo['escenario'] == escenario]
                df_scene = df_esc[df_esc['tipo_evento'] == 'SCENE']
                
                if not df_scene.empty:
                    df_valid = df_scene[
                        (df_scene['objeto_verdad'].notna()) & 
                        (df_scene['objeto_verdad'] != '')
                    ]
                    if not df_valid.empty:
                        aciertos = (df_valid['objeto_verdad'] == df_valid['objeto_predicho']).sum()
                        precision = (aciertos / len(df_valid) * 100) if len(df_valid) > 0 else 0
                        escenarios[f"{escenario}_{modo}_SCENE"] = round(precision, 2)
        
        table = r"""\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{Xcc}
\toprule
\textbf{Escenario de prueba} & \textbf{Modo Local (\%)} & \textbf{Modo H√≠brido - Scene (\%)} \\
\midrule"""
        
        esc_unicos = sorted(set([k.split('_')[0] for k in escenarios.keys()]))
        for esc in esc_unicos:
            local_val = escenarios.get(f"{esc}_LOCAL_SCENE", 'N/A')
            mobile_val = escenarios.get(f"{esc}_MOBILE_SCENE", 'N/A')
            table += f"\nEscenario {esc} & {local_val} & {mobile_val} \\\\"
        
        table += r"""
\bottomrule
\end{tabularx}
\caption{Precisi√≥n por escenario de prueba}
\label{tab:precision-escenario}
\end{table}"""
        
        return table
    
    def _generate_latencia_sistema_table(self):
        """Tabla 3: Latencia del sistema"""
        m = self.metrics
        
        def get_lat(key, field, default=0):
            val = m.get(key, {}).get(field, default)
            return f"{val:.0f}" if val != 0 else "N/A"
        
        table = r"""\begin{table}[H]
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Modalidad} & \textbf{Media (ms)} & \textbf{SD (ms)} & \textbf{M√≠n (ms)} & \textbf{M√°x (ms)} \\
\midrule"""
        
        table += f"\nModo Local & {get_lat('LOCAL', 'latencia_media_ms')} & {get_lat('LOCAL', 'latencia_sd_ms')} & {get_lat('LOCAL', 'latencia_min_ms')} & {get_lat('LOCAL', 'latencia_max_ms')} \\\\"
        table += f"\nModo H√≠brido - Scene & {get_lat('MOBILE_SCENE', 'latencia_media_ms')} & {get_lat('MOBILE_SCENE', 'latencia_sd_ms')} & {get_lat('MOBILE_SCENE', 'latencia_min_ms')} & {get_lat('MOBILE_SCENE', 'latencia_max_ms')} \\\\"
        table += f"\nModo H√≠brido - OCR & {get_lat('MOBILE_OCR', 'latencia_media_ms')} & {get_lat('MOBILE_OCR', 'latencia_sd_ms')} & {get_lat('MOBILE_OCR', 'latencia_min_ms')} & {get_lat('MOBILE_OCR', 'latencia_max_ms')} \\\\"
        table += f"\nModo H√≠brido - Depth & {get_lat('MOBILE_DEPTH', 'latencia_media_ms')} & {get_lat('MOBILE_DEPTH', 'latencia_sd_ms')} & {get_lat('MOBILE_DEPTH', 'latencia_min_ms')} & {get_lat('MOBILE_DEPTH', 'latencia_max_ms')} \\\\"
        
        table += r"""
\bottomrule
\end{tabular}
\caption{Latencia del sistema por modalidad}
\label{tab:latencia-sistema}
\end{table}"""
        
        return table
    
    def _generate_latencia_componentes_table(self):
        """Tabla 4: Latencia por componentes"""
        print("\n" + "="*60)
        print("üìä CALCULANDO LATENCIAS POR COMPONENTE")
        print("="*60)
        
        componentes = {
            'SCENE': {'captura': [], 'preprocesamiento': [], 'inferencia': [], 'audio': []},
            'OCR': {'captura': [], 'preprocesamiento': [], 'inferencia': [], 'audio': []},
            'DEPTH': {'captura': [], 'preprocesamiento': [], 'inferencia': [], 'audio': []}
        }
        
        # SCENE
        df_scene = self.df[(self.df['modo'] == 'MOBILE') & (self.df['tipo_evento'].isin(['ESP32', 'SCENE', 'TTS']))].copy()
        
        captures = df_scene[
            (df_scene['tipo_evento'] == 'ESP32') & 
            (df_scene['notas'].str.contains('finished.*bytes', na=False, regex=True)) &
            (df_scene['t_total_ms_numeric'].notna())
        ]
        componentes['SCENE']['captura'] = captures['t_total_ms_numeric'].tolist()
        
        preproc = df_scene[
            (df_scene['tipo_evento'] == 'SCENE') &
            (df_scene['notas'].str.contains('resizing to', na=False, case=False)) &
            (df_scene['t_total_ms_numeric'].notna())
        ]
        componentes['SCENE']['preprocesamiento'] = preproc['t_total_ms_numeric'].tolist()
        
        inference = df_scene[
            (df_scene['tipo_evento'] == 'SCENE') &
            (df_scene['notas'].str.contains('finished inference', na=False, case=False)) &
            (df_scene['t_total_ms_numeric'].notna())
        ]
        componentes['SCENE']['inferencia'] = inference['t_total_ms_numeric'].tolist()
        
        tts = df_scene[
            (df_scene['tipo_evento'] == 'TTS') &
            (df_scene['notas'].str.contains('converted output to speech', na=False, case=False)) &
            (df_scene['t_total_ms_numeric'].notna())
        ]
        componentes['SCENE']['audio'] = tts['t_total_ms_numeric'].tolist()
        
        # OCR
        df_ocr = self.df[(self.df['modo'] == 'MOBILE') & (self.df['tipo_evento'].isin(['ESP32', 'OCR', 'TTS']))].copy()
        
        captures = df_ocr[
            (df_ocr['tipo_evento'] == 'ESP32') &
            (df_ocr['notas'].str.contains('finished.*bytes', na=False, regex=True)) &
            (df_ocr['t_total_ms_numeric'].notna())
        ]
        componentes['OCR']['captura'] = captures['t_total_ms_numeric'].tolist()
        
        preproc = df_ocr[
            (df_ocr['tipo_evento'] == 'OCR') &
            (df_ocr['notas'].str.contains('upscaled to', na=False, case=False)) &
            (df_ocr['t_total_ms_numeric'].notna())
        ]
        componentes['OCR']['preprocesamiento'] = preproc['t_total_ms_numeric'].tolist()
        
        inference = df_ocr[
            (df_ocr['tipo_evento'] == 'OCR') &
            (df_ocr['notas'].str.contains('result:', na=False, case=False)) &
            (df_ocr['t_total_ms_numeric'].notna()) &
            (df_ocr['t_total_ms_numeric'] > 0.1)
        ]
        componentes['OCR']['inferencia'] = inference['t_total_ms_numeric'].tolist()
        
        tts = df_ocr[
            (df_ocr['tipo_evento'] == 'TTS') &
            (df_ocr['notas'].str.contains('converted output to speech', na=False, case=False)) &
            (df_ocr['t_total_ms_numeric'].notna())
        ]
        componentes['OCR']['audio'] = tts['t_total_ms_numeric'].tolist()
        
        # DEPTH
        df_depth = self.df[(self.df['modo'] == 'MOBILE') & (self.df['tipo_evento'].isin(['ESP32', 'DEPTH', 'TTS']))].copy()
        
        captures = df_depth[
            (df_depth['tipo_evento'] == 'ESP32') &
            (df_depth['notas'].str.contains('finished.*bytes', na=False, regex=True)) &
            (df_depth['t_total_ms_numeric'].notna())
        ]
        componentes['DEPTH']['captura'] = captures['t_total_ms_numeric'].tolist()
        
        preproc = df_depth[
            (df_depth['tipo_evento'] == 'DEPTH') &
            (df_depth['notas'].str.contains('resizing to', na=False, case=False)) &
            (df_depth['t_total_ms_numeric'].notna())
        ]
        componentes['DEPTH']['preprocesamiento'] = preproc['t_total_ms_numeric'].tolist()
        
        inference = df_depth[
            (df_depth['tipo_evento'] == 'DEPTH') &
            (df_depth['notas'].str.contains('done. minDistance', na=False, case=False)) &
            (df_depth['t_total_ms_numeric'].notna())
        ]
        componentes['DEPTH']['inferencia'] = inference['t_total_ms_numeric'].tolist()
        
        tts = df_depth[
            (df_depth['tipo_evento'] == 'TTS') &
            (df_depth['notas'].str.contains('converted output to speech', na=False, case=False)) &
            (df_depth['t_total_ms_numeric'].notna())
        ]
        componentes['DEPTH']['audio'] = tts['t_total_ms_numeric'].tolist()
        
        def calc_mean_ms(values):
            if not values:
                return 0
            return np.mean(values) * 1000
        
        scene_cap = calc_mean_ms(componentes['SCENE']['captura'])
        scene_pre = calc_mean_ms(componentes['SCENE']['preprocesamiento'])
        scene_inf = calc_mean_ms(componentes['SCENE']['inferencia'])
        scene_aud = calc_mean_ms(componentes['SCENE']['audio'])
        scene_wifi = 50
        scene_total = scene_cap + scene_pre + scene_wifi + scene_inf + scene_aud
        
        ocr_cap = calc_mean_ms(componentes['OCR']['captura'])
        ocr_pre = calc_mean_ms(componentes['OCR']['preprocesamiento'])
        ocr_inf = calc_mean_ms(componentes['OCR']['inferencia'])
        ocr_aud = calc_mean_ms(componentes['OCR']['audio'])
        ocr_wifi = 50
        ocr_total = ocr_cap + ocr_pre + ocr_wifi + ocr_inf + ocr_aud
        
        depth_cap = calc_mean_ms(componentes['DEPTH']['captura'])
        depth_pre = calc_mean_ms(componentes['DEPTH']['preprocesamiento'])
        depth_inf = calc_mean_ms(componentes['DEPTH']['inferencia'])
        depth_aud = calc_mean_ms(componentes['DEPTH']['audio'])
        depth_wifi = 50
        depth_total = depth_cap + depth_pre + depth_wifi + depth_inf + depth_aud
        
        # Calcular LOCAL components si est√°n disponibles
        local_cap = 0
        local_inf = 0
        if self.local_parser and self.local_parser.results:
            metrics = self.local_parser.calculate_local_metrics()
            if metrics:
                local_cap = metrics.get('latencia_envio_media_ms', 0)
                local_inf = metrics.get('inference_time_media_ms', 0)
        
        local_total = local_cap + local_inf if (local_cap or local_inf) else 0
        
        table = r"""\begin{table}[H]
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Componente} & \textbf{Modo Local (ms)} & \textbf{Scene (ms)} & \textbf{OCR (ms)} & \textbf{Depth (ms)} \\
\midrule"""
        
        local_cap_str = f"{local_cap:.0f}" if local_cap else "N/A"
        local_inf_str = f"{local_inf:.0f}" if local_inf else "N/A"
        local_total_str = f"{local_total:.0f}" if local_total else "N/A"
        
        table += f"\nCaptura de imagen & {local_cap_str} & {scene_cap:.0f} & {ocr_cap:.0f} & {depth_cap:.0f} \\\\"
        table += f"\nPreprocesamiento & N/A & {scene_pre:.0f} & {ocr_pre:.0f} & {depth_pre:.0f} \\\\"
        table += f"\nTransmisi√≥n WiFi & N/A & {scene_wifi:.0f} & {ocr_wifi:.0f} & {depth_wifi:.0f} \\\\"
        table += f"\nInferencia & {local_inf_str} & {scene_inf:.0f} & {ocr_inf:.0f} & {depth_inf:.0f} \\\\"
        table += f"\nGeneraci√≥n audio & N/A & {scene_aud:.0f} & {ocr_aud:.0f} & {depth_aud:.0f} \\\\"
        table += "\n\\midrule"
        table += f"\n\\textbf{{Total}} & \\textbf{{{local_total_str}}} & \\textbf{{{scene_total:.0f}}} & \\textbf{{{ocr_total:.0f}}} & \\textbf{{{depth_total:.0f}}} \\\\"
        
        table += r"""
\bottomrule
\end{tabular}
\caption{Desglose de latencia por componente del sistema}
\label{tab:latencia-componentes}
\end{table}"""
        
        return table
    
    def _generate_tasa_fallos_table(self):
        """Tabla 5: Tasa de fallos"""
        m = self.metrics
        
        def get_val(key, field, default=0):
            return m.get(key, {}).get(field, default)
        
        table = r"""\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Modalidad} & \textbf{Pruebas totales} & \textbf{Fallos} & \textbf{Tasa de fallos (\%)} \\
\midrule"""
        
        table += f"\nModo Local & {get_val('LOCAL', 'n_pruebas', 0)} & {get_val('LOCAL', 'fallos', 0)} & {get_val('LOCAL', 'tasa_fallos_pct', 0):.2f} \\\\"
        table += f"\nModo H√≠brido - Scene & {get_val('MOBILE_SCENE', 'n_pruebas', 0)} & {get_val('MOBILE_SCENE', 'fallos', 0)} & {get_val('MOBILE_SCENE', 'tasa_fallos_pct', 0):.2f} \\\\"
        table += f"\nModo H√≠brido - OCR & {get_val('MOBILE_OCR', 'n_pruebas', 0)} & {get_val('MOBILE_OCR', 'fallos', 0)} & {get_val('MOBILE_OCR', 'tasa_fallos_pct', 0):.2f} \\\\"
        table += f"\nModo H√≠brido - Depth & {get_val('MOBILE_DEPTH', 'n_pruebas', 0)} & {get_val('MOBILE_DEPTH', 'fallos', 0)} & {get_val('MOBILE_DEPTH', 'tasa_fallos_pct', 0):.2f} \\\\"
        
        table += r"""
\bottomrule
\end{tabular}
\caption{Tasa de fallos por modalidad}
\label{tab:robustez}
\end{table}"""
        
        return table
    
    def plot_individual_metrics(self):
        """Genera gr√°ficos individuales"""
        print("\nüìä Generando gr√°ficos individuales...")
        
        # 1. Precisi√≥n OCR
        fig1, ax1 = plt.subplots(figsize=(12, 6))
        df_ocr = self.df[self.df['tipo_evento'] == 'OCR'].copy()
        df_ocr_valid = df_ocr[
            (df_ocr['texto_verdad'].notna()) & 
            (df_ocr['texto_predicho'].notna())
        ].copy()
        
        if not df_ocr_valid.empty:
            df_ocr_valid['acierto'] = df_ocr_valid.apply(
                lambda row: 1 if self.calculate_text_similarity(
                    str(row['texto_verdad']), str(row['texto_predicho'])
                ) >= 0.8 else 0, axis=1
            )
            precision_data = df_ocr_valid.groupby('escenario')['acierto'].apply(
                lambda x: (x.sum() / len(x) * 100)
            ).round(2)
            
            precision_data.plot(kind='bar', ax=ax1, color='steelblue', alpha=0.7)
            ax1.set_title('Precisi√≥n por Escenario (OCR)', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Escenario')
            ax1.set_ylabel('Precisi√≥n (%)')
            ax1.grid(True, alpha=0.3)
            ax1.axhline(y=80, color='g', linestyle='--', alpha=0.5, label='Target 80%')
            ax1.legend()
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, '01_precision_ocr.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        # 2. Error DEPTH
        fig2, ax2 = plt.subplots(figsize=(12, 6))
        df_depth = self.df[
            (self.df['tipo_evento'] == 'DEPTH') &
            (self.df['diferencia_distancia_pct'].notna())
        ].copy()
        
        if not df_depth.empty:
            error_means = df_depth.groupby('escenario')['diferencia_distancia_pct'].mean()
            error_means.plot(kind='bar', ax=ax2, color='coral', alpha=0.7)
            ax2.set_title('Error Medio de Distancia (DEPTH)', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Escenario')
            ax2.set_ylabel('Error (%)')
            ax2.grid(True, alpha=0.3)
            ax2.axhline(y=20, color='g', linestyle='--', alpha=0.5, label='Umbral Acierto (20%)')
            ax2.axhline(y=50, color='r', linestyle='--', alpha=0.5, label='Umbral Fallo (50%)')
            ax2.legend()
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, '02_error_depth.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        # 3. Clasificaci√≥n DEPTH (pie chart)
        fig3, ax3 = plt.subplots(figsize=(8, 8))
        if not df_depth.empty:
            classification_counts = df_depth['clasificacion_distancia'].value_counts()
            colors = {'Acierto': 'green', 'Error parcial': 'orange', 'Fallo': 'red'}
            ax3.pie(classification_counts, labels=classification_counts.index,
                   autopct='%1.1f%%', colors=[colors.get(x, 'gray') for x in classification_counts.index],
                   startangle=90)
            ax3.set_title('Clasificaci√≥n de Distancias (DEPTH)', fontsize=14, fontweight='bold')
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, '03_clasificacion_depth.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        # 4. Tasa detecci√≥n SCENE
        fig4, ax4 = plt.subplots(figsize=(12, 6))
        df_scene = self.df[self.df['tipo_evento'] == 'SCENE'].copy()
        if not df_scene.empty:
            scene_by_scenario = df_scene.groupby('escenario').apply(
                lambda x: ((x['objeto_predicho'].notna() & 
                           (x['objeto_predicho'] != 'unknown')).sum() / len(x) * 100)
            ).round(2)
            
            scene_by_scenario.plot(kind='bar', ax=ax4, color='mediumpurple', alpha=0.7)
            ax4.set_title('Tasa de Detecci√≥n SCENE por Escenario', fontsize=14, fontweight='bold')
            ax4.set_xlabel('Escenario')
            ax4.set_ylabel('Tasa de Detecci√≥n (%)')
            ax4.grid(True, alpha=0.3)
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, '04_tasa_deteccion_scene.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        # 5. Latencia por componente
        fig5, ax5 = plt.subplots(figsize=(10, 6))
        df_component = self.df[self.df['t_total_ms_numeric'].notna()].copy()
        if not df_component.empty:
            latency_comp = df_component.groupby('tipo_evento')['t_total_ms_numeric'].mean().sort_values(ascending=True)
            latency_comp.plot(kind='barh', ax=ax5, color='teal', alpha=0.7)
            ax5.set_title('Latencia Media por Componente', fontsize=14, fontweight='bold')
            ax5.set_xlabel('Latencia (s)')
            ax5.set_ylabel('Componente')
            ax5.grid(True, alpha=0.3, axis='x')
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, '05_latencia_componente.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        # 6. Distribuci√≥n latencias
        fig6, ax6 = plt.subplots(figsize=(10, 6))
        df_latency = self.df[self.df['latencia_ms'].notna()]
        if not df_latency.empty:
            for modo in df_latency['modo'].unique():
                data = df_latency[df_latency['modo'] == modo]['latencia_ms']
                ax6.hist(data, bins=20, alpha=0.5, label=modo)
            ax6.set_title('Distribuci√≥n de Latencias', fontsize=14, fontweight='bold')
            ax6.set_xlabel('Latencia (s)')
            ax6.set_ylabel('Frecuencia')
            ax6.legend()
            ax6.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, '06_distribucion_latencias.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        # 7. Matriz de confusi√≥n LOCAL (si existe)
        if self.local_parser and self.local_parser.results:
            self.local_parser.generate_confusion_matrix()
        
        print(f"‚úÖ Gr√°ficos individuales guardados en '{output_dir}'")
    
    def generate_report(self):
        """Genera reporte completo"""
        if not self.load_data():
            return
        
        print("\n" + "="*60)
        print("üìã REPORTE DE AN√ÅLISIS COMPLETO")
        print("="*60)
        
        # Si hay parser local, mostrar sus m√©tricas
        if self.local_parser and self.local_parser.results:
            print("\n" + "="*60)
            print("üìä AN√ÅLISIS DEL MODO LOCAL")
            print("="*60)
            
            # Generar CSV simple
            self.local_parser.generate_simple_results_csv()
            
            # Calcular y mostrar m√©tricas
            metrics = self.local_parser.calculate_local_metrics()
            self.local_parser.print_metrics_summary(metrics)
        
        # Calcular m√©tricas generales
        self.calculate_all_metrics()
        
        # Generar tablas LaTeX
        self.generate_latex_tables()
        
        # Generar gr√°ficos
        self.plot_individual_metrics()
        
        # Guardar CSV integrado
        output_csv = os.path.join(output_dir, "resultados_integrados.csv")
        self.df.to_csv(output_csv, index=False, encoding='utf-8')
        print(f"\n‚úÖ CSV integrado guardado: {output_csv}")
        
        print("\n‚úÖ An√°lisis completado")


if __name__ == "__main__":
    print("="*60)
    print("üöÄ ANALIZADOR DE PRUEBAS DE VISI√ìN ARTIFICIAL")
    print("="*60)
    
    # Configurar paths
    csv_hibrido = "resultados_pruebas_20260104_161812.csv"
    log_local = "./logs/ESP - 2 - 4.1 - 4.2.log"
    ground_truth = "esp32_test.csv"
    
    # Verificar si existen los archivos
    has_hibrido = os.path.exists(csv_hibrido)
    has_local = os.path.exists(log_local) and os.path.exists(ground_truth)
    
    if not has_hibrido and not has_local:
        print("\n‚ùå No se encontraron archivos de entrada")
        print(f"   Buscando: {csv_hibrido}")
        print(f"   Buscando: {log_local}")
        print(f"   Buscando: {ground_truth}")
    else:
        # Crear analizador con o sin logs locales
        if has_local:
            print("\n‚úÖ Modo: AN√ÅLISIS COMPLETO (Local + H√≠brido)")
            analyzer = TestAnalyzer(
                csv_path=csv_hibrido if has_hibrido else None,
                local_log_path=log_local,
                ground_truth_csv=ground_truth
            )
        else:
            print("\n‚úÖ Modo: AN√ÅLISIS H√çBRIDO")
            analyzer = TestAnalyzer(csv_path=csv_hibrido)
        
        # Generar reporte
        analyzer.generate_report()